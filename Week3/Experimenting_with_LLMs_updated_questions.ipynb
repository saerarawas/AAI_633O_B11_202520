{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_633O_B11_202520/blob/main/Week3/Experimenting_with_LLMs_updated_questions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 3 Hands-on Lab: Experimenting With Large Language Models**"
      ],
      "metadata": {
        "id": "3fI1offS40zi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction:**\n",
        "\n",
        "In this hands-on python notebook, we willl be experimenting with LLMs.\n",
        "This will help you:\n",
        "1.\tUse a pre-trained LLM from the Hugging Face library for text summarization.\n",
        "2.\tImplement a question-answering task using a pre-trained LLM.\n",
        "3.\tUnderstand how LLMs perform NLP tasks in real-world scenarios.\n"
      ],
      "metadata": {
        "id": "ff4LHilX5Kf9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Text Summarization**"
      ],
      "metadata": {
        "id": "UDx0zQPu5rpm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Import Necessary Libraries**\n",
        "\n",
        "We will be using the [Transformers](https://huggingface.co/docs/transformers/en/index) library from [Hugging Face](https://huggingface.co/). The Transformers library provides APIs and tools to easily download and train state-of-the-art pretrained models."
      ],
      "metadata": {
        "id": "OLvntDtm5y3K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PsDc_idx40Jt"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Set up the Summarization Pipeline**"
      ],
      "metadata": {
        "id": "n8RiZlIv6C6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the summarization pipeline\n",
        "summarizer = pipeline(\"summarization\")\n",
        "\n",
        "# Input a long text for summarization\n",
        "long_text = \"\"\"\n",
        "Artificial intelligence (AI) is rapidly transforming industries, from healthcare and education to finance and entertainment.\n",
        "Generative AI models, such as Large Language Models (LLMs), are at the forefront of this transformation. These models are\n",
        "trained on vast datasets and can generate human-like text, enabling applications like automated customer support,\n",
        "personalized education tools, and content creation. Despite their potential, challenges such as bias, ethical concerns,\n",
        "and the environmental impact of large-scale training persist. Addressing these challenges is crucial for the responsible\n",
        "deployment of AI technologies in the future.\n",
        "\"\"\"\n",
        "\n",
        "# Generate a summary\n",
        "summary = summarizer(long_text, max_length=20, min_length=10, do_sample=False)\n",
        "print(\"Summary:\")\n",
        "print(summary[0]['summary_text'])\n"
      ],
      "metadata": {
        "id": "rCq2G0236HgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c69265-4535-404e-fd46-01f943e7d5d8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Artificial intelligence (AI) is rapidly transforming industries, from healthcare and education to finance and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I set the Max to 20 and Min to 10, the summary is less than provided"
      ],
      "metadata": {
        "id": "E2HunS7DvPlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Experiment**\n",
        "\n",
        "* Replace long_text with any article or paragraph of your choice.\n",
        "* Try different max_length and min_length values to see how they affect the summary.\n"
      ],
      "metadata": {
        "id": "hiFUwWrZ6Sa9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Question Answering**"
      ],
      "metadata": {
        "id": "24nKFnb56mhi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tSet Up the Question-Answering Pipeline**"
      ],
      "metadata": {
        "id": "RHIEB48L6qQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the question-answering pipeline\n",
        "qa_pipeline = pipeline(\"question-answering\")\n",
        "\n",
        "# Input context and questions\n",
        "context = \"\"\"\n",
        "The Large Language Model (LLM) GPT-3, developed by OpenAI, is known for its exceptional ability to generate human-like text.\n",
        "It uses the Transformer architecture and has 175 billion parameters, making it one of the largest AI models in the world.\n",
        "LLMs like GPT-3 are widely used in applications such as content creation, summarization, and question answering.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Which applications are used?\"\n",
        "\n",
        "# Get the answer\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "print(\"Answer:\")\n",
        "print(answer['answer'])\n"
      ],
      "metadata": {
        "id": "xbFCfzNi6V3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e5dc2b-9788-4b94-94cb-516fd9f82cfe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer:\n",
            "content creation, summarization, and question answering\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I changed the question to: What applications are used?"
      ],
      "metadata": {
        "id": "SpI4ISYyvZ_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.\tExperiment**\n",
        "\n",
        "* Modify the context and question variables with your own text and queries.\n",
        "* Observe how the model adjusts its answers based on the provided input\n"
      ],
      "metadata": {
        "id": "Otq9wqZc6y93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3: Combine Summarization and Question Answering**"
      ],
      "metadata": {
        "id": "negGMYGt64tG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Pipeline Integration**\n",
        "\n",
        "Combine the two pipelines to first summarize a long text and then extract answers to specific questions from the summary.\n"
      ],
      "metadata": {
        "id": "1OrgCwu669OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the text\n",
        "summary = summarizer(long_text, max_length=50, min_length=25, do_sample=False)[0]['summary_text']\n",
        "\n",
        "# Define a question based on the summary\n",
        "question = \"What is Artifical Intelligence transforming?\"\n",
        "# Use the QA pipeline to extract the answer\n",
        "answer = qa_pipeline(question=question, context=summary)\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", answer['answer'])\n"
      ],
      "metadata": {
        "id": "oM6KZs_V7F0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af3e5fb-840a-49d1-e116-b79c3f353491"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is Artifical Intelligence transforming?\n",
            "Answer: industries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I changed the question to : What is Artificial Intelligence transforming?"
      ],
      "metadata": {
        "id": "duLYpwsUwKeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Experiment**\n",
        "\n",
        "•\tChange the input text and questions to test the robustness of the combined approach.\n"
      ],
      "metadata": {
        "id": "vAyjeci67JVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary:**\n",
        "\n",
        "By completing this activity, you have:\n",
        "\n",
        "* Gained hands-on experience using LLMs for real-world NLP tasks.\n",
        "* Understood the capabilities and limitations of pre-trained LLMs.\n",
        "* Appreciated the practical applications of LLMs in summarization and question answering.\n",
        "\n",
        "This activity ensures practical understanding of LLMs while showcasing their real-world relevance. Let me know if you’d like additional extensions!\n"
      ],
      "metadata": {
        "id": "a1pbj-m07hyw"
      }
    }
  ]
}