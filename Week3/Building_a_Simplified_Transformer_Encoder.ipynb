{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_633O_B11_202520/blob/main/Week3/Building_a_Simplified_Transformer_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 3 Hands-on Lab: Building a Simplified Transformer Encoder**"
      ],
      "metadata": {
        "id": "UvODY4XYGS4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This hands-on lab allows you to understand the Transformer architecture by implementing a basic Transformer encoder. You will learn how input embeddings, positional encodings, and feedforward layers work together in an encoder block. We will be using the Torch framework to build a simple transformer encoder."
      ],
      "metadata": {
        "id": "tV7jIspzGcIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Input Embedding and Positional Encoding**"
      ],
      "metadata": {
        "id": "UD0bA42xGnZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tGenerate Input Data**\n",
        "Define a sample sentence and tokenize it into a numerical format.\n"
      ],
      "metadata": {
        "id": "B-uZW8_bGvUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Example sentence and token IDs (simplified for illustration)\n",
        "token_ids = torch.tensor([[1, 2, 3, 4, 5]])  # Tokenized sentence\n",
        "vocab_size = 10  # Vocabulary size\n",
        "embedding_dim = 8  # Embedding size"
      ],
      "metadata": {
        "id": "bulopUQ1GzrC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Create an Embedding Layer**\n",
        "Implement the embedding layer to convert token IDs into dense vectors."
      ],
      "metadata": {
        "id": "4khCooiqIdHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedded_tokens = embedding_layer(token_ids)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens)"
      ],
      "metadata": {
        "id": "LjWIeI7GIoEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0979bc-5e15-4228-8cb4-564c83ff7296"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedded Tokens:\n",
            " tensor([[[-0.0476,  0.5313, -1.8818, -0.2800, -0.0036,  0.4372, -0.0532,\n",
            "           0.1149],\n",
            "         [ 0.1361, -0.6000, -1.2875,  0.7560,  1.3221,  0.6297, -1.9284,\n",
            "          -0.7103],\n",
            "         [ 0.3835,  2.5033,  0.0379,  1.3129,  1.0807,  0.6865, -0.0671,\n",
            "           1.2258],\n",
            "         [ 0.6793,  0.8648,  0.0030,  1.3668, -2.3055,  1.6827, -0.7441,\n",
            "           1.3466],\n",
            "         [ 0.7979, -1.0823, -1.8698, -1.6705, -0.5799,  0.1817,  0.8907,\n",
            "          -1.6750]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tAdd Positional Encoding**\n",
        "Incorporate positional encoding to provide positional information to the model.\n"
      ],
      "metadata": {
        "id": "EfdPOMcpG_qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(seq_len, embedding_dim):\n",
        "    position = np.arange(seq_len)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
        "    pe = np.zeros((seq_len, embedding_dim))\n",
        "    pe[:, 0::2] = np.sin(position * div_term)\n",
        "    pe[:, 1::2] = np.cos(position * div_term)\n",
        "    return torch.tensor(pe, dtype=torch.float)\n",
        "\n",
        "seq_len = token_ids.size(1)\n",
        "pos_encoding = positional_encoding(seq_len, embedding_dim)\n",
        "print(\"Positional Encoding:\\n\", pos_encoding)\n"
      ],
      "metadata": {
        "id": "Mti1h0tXHDXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d765687-0c3f-4aa5-a22c-c7fef9ff9aea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encoding:\n",
            " tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9996e-02,\n",
            "          9.9955e-01,  3.0000e-03,  1.0000e+00],\n",
            "        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n",
            "          9.9920e-01,  4.0000e-03,  9.9999e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the positional encoding to the embedded tokens:"
      ],
      "metadata": {
        "id": "iZm2hKp-HIxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_with_pos = embedded_tokens + pos_encoding.unsqueeze(0)\n",
        "print(\"Embedded Tokens with Positional Encoding:\\n\", embedded_with_pos)\n"
      ],
      "metadata": {
        "id": "TMwXiAIiHLm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "085abebf-5d64-4fdb-f913-4e4ff47db9d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedded Tokens with Positional Encoding:\n",
            " tensor([[[-0.0476,  1.5313, -1.8818,  0.7200, -0.0036,  1.4372, -0.0532,\n",
            "           1.1149],\n",
            "         [ 0.9775, -0.0597, -1.1877,  1.7510,  1.3321,  1.6296, -1.9274,\n",
            "           0.2897],\n",
            "         [ 1.2928,  2.0872,  0.2366,  2.2930,  1.1007,  1.6863, -0.0651,\n",
            "           2.2258],\n",
            "         [ 0.8204, -0.1252,  0.2985,  2.3221, -2.2755,  2.6823, -0.7411,\n",
            "           2.3466],\n",
            "         [ 0.0411, -1.7360, -1.4803, -0.7494, -0.5399,  1.1809,  0.8947,\n",
            "          -0.6750]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Add a Feedforward Layer**"
      ],
      "metadata": {
        "id": "wfM3VX60HQ6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define a Feedforward Neural Network**\n",
        "Implement a simple feedforward layer as part of the encoder.\n"
      ],
      "metadata": {
        "id": "oUaKhCEuHViQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedforward = nn.Sequential(\n",
        "    nn.Linear(embedding_dim, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, embedding_dim)\n",
        ")\n",
        "ff_output = feedforward(embedded_with_pos)\n",
        "print(\"Feedforward Output:\\n\", ff_output)\n"
      ],
      "metadata": {
        "id": "RIN1MxZVHZwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6e94ed-36bf-42c3-cdaa-651cc75cdeaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedforward Output:\n",
            " tensor([[[-0.3757,  0.5520, -0.4770,  0.2611, -0.1558, -0.2438, -0.3839,\n",
            "           0.6963],\n",
            "         [-0.0732,  0.3629, -0.2447,  0.1214,  0.1462,  0.0155,  0.0546,\n",
            "           0.2149],\n",
            "         [-0.3086,  0.2660, -0.6446,  0.5495,  0.2360, -0.0111, -0.1559,\n",
            "           1.0200],\n",
            "         [-0.0326,  0.1907, -0.8252,  0.5016,  0.3373, -0.0055,  0.0163,\n",
            "           1.2718],\n",
            "         [ 0.1800,  0.3794,  0.1056, -0.1509,  0.1604,  0.2099,  0.2076,\n",
            "          -0.0501]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3: Combine the Components into an Encoder Block**"
      ],
      "metadata": {
        "id": "xb9uak0OHcjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define the Encoder Block**\n",
        "Combine the embedding, positional encoding, and feedforward components into an encoder block.\n"
      ],
      "metadata": {
        "id": "qXVdYvwkHgdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, embedding_dim)\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        pos_enc = positional_encoding(x.size(1), embed.size(2))\n",
        "        embed_with_pos = embed + pos_enc.unsqueeze(0)\n",
        "        ff_output = self.feedforward(embed_with_pos)\n",
        "        return self.layer_norm(embed_with_pos + ff_output)\n",
        "\n",
        "encoder = TransformerEncoderBlock(vocab_size, embedding_dim)\n",
        "output = encoder(token_ids)\n",
        "print(\"Encoder Output:\\n\", output)\n"
      ],
      "metadata": {
        "id": "70IMzzkPHmRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa0076b-c533-4924-b40c-4bfcbb849fa8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output:\n",
            " tensor([[[ 0.6291,  0.9954,  0.0744, -1.1658, -0.4841,  1.5911, -0.0660,\n",
            "          -1.5743],\n",
            "         [-1.1803, -0.2941, -0.8616,  0.8310, -0.9540,  2.0155,  0.1298,\n",
            "           0.3137],\n",
            "         [ 1.4635,  0.2129,  0.4341, -1.1405, -1.3900,  0.2033,  1.1868,\n",
            "          -0.9702],\n",
            "         [-0.3388, -0.4817, -0.2582,  2.0535, -0.1916, -0.8219,  1.1719,\n",
            "          -1.1332],\n",
            "         [-0.4899, -0.1472,  0.9754,  1.1978,  0.5335, -1.2628,  0.8510,\n",
            "          -1.6579]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4: Experiment with Different Inputs**\n",
        "\n",
        "* Test with Different Sentences\n",
        "Replace token_ids with new examples to observe how the encoder processes different inputs.\n",
        "* Modify Hyperparameters\n",
        "Experiment with different embedding sizes, feedforward dimensions, or positional encoding scales to see their effect on the output.\n"
      ],
      "metadata": {
        "id": "zfB-L5zlHqhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**"
      ],
      "metadata": {
        "id": "IZW4m09oIIFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By completing this lab, you have:\n",
        "\n",
        "* Understood the role of embedding, positional encoding, and feedforward layers in the Transformer encoder.\n",
        "* Gained hands-on experience implementing a core component of the Transformer architecture.\n",
        "* Developed a deeper appreciation for the architectureâ€™s design and functionality.\n",
        "\n",
        "This lab builds foundational knowledge of the Transformer, preparing you for more advanced concepts like self-attention.\n"
      ],
      "metadata": {
        "id": "49Ko4E9cH4df"
      }
    }
  ]
}