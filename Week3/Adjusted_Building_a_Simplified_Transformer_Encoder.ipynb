{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saerarawas/AAI_633O_B11_202520/blob/main/Week3/Adjusted_Building_a_Simplified_Transformer_Encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Week 3 Hands-on Lab: Building a Simplified Transformer Encoder**"
      ],
      "metadata": {
        "id": "UvODY4XYGS4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This hands-on lab allows you to understand the Transformer architecture by implementing a basic Transformer encoder. You will learn how input embeddings, positional encodings, and feedforward layers work together in an encoder block. We will be using the Torch framework to build a simple transformer encoder."
      ],
      "metadata": {
        "id": "tV7jIspzGcIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: Input Embedding and Positional Encoding**"
      ],
      "metadata": {
        "id": "UD0bA42xGnZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.\tGenerate Input Data**\n",
        "Define a sample sentence and tokenize it into a numerical format.\n"
      ],
      "metadata": {
        "id": "B-uZW8_bGvUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# Example sentence and token IDs (simplified for illustration)\n",
        "token_ids = torch.tensor([[1, 2, 3, 4, 5]])  # Tokenized sentence\n",
        "vocab_size = 10  # Vocabulary size\n",
        "embedding_dim = 8  # Embedding size"
      ],
      "metadata": {
        "id": "bulopUQ1GzrC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define tokenized sentences (IDs should be within vocab_size)\n",
        "token_ids_1 = torch.tensor([[1, 2, 3, 4, 5]])  # Example 1\n",
        "token_ids_2 = torch.tensor([[6, 7, 8, 9, 2]])  # Example 2\n",
        "token_ids_3 = torch.tensor([[3, 5, 7, 1, 9]])  # Example 3\n",
        "\n",
        "# Parameters\n",
        "vocab_size = 10  # Vocabulary size\n",
        "embedding_dim = 8  # Embedding size\n",
        "\n",
        "# Define embedding layer\n",
        "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "# Get embeddings\n",
        "embedding_1 = embedding(token_ids_1)\n",
        "embedding_2 = embedding(token_ids_2)\n",
        "embedding_3 = embedding(token_ids_3)\n",
        "\n",
        "# Print results\n",
        "print(\"Embeddings for Sentence 1:\\n\", embedding_1)\n",
        "print(\"\\nEmbeddings for Sentence 2:\\n\", embedding_2)\n",
        "print(\"\\nEmbeddings for Sentence 3:\\n\", embedding_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da1gzrPMCurS",
        "outputId": "667cf4ff-c369-4ab1-c705-842cd0633346"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings for Sentence 1:\n",
            " tensor([[[ 1.2439, -0.3636,  0.1571,  0.1304,  1.7929,  0.5730,  0.2452,\n",
            "          -0.7472],\n",
            "         [ 1.1265, -0.1054,  0.1853, -1.2709,  0.1538,  0.2244,  0.6790,\n",
            "           0.5241],\n",
            "         [ 0.7050, -0.0054, -0.7490,  1.6957,  0.4317,  1.0350, -2.0611,\n",
            "          -0.4975],\n",
            "         [ 0.7463, -0.1773,  0.3654, -0.6961,  1.5702,  0.2138, -1.9310,\n",
            "           0.0756],\n",
            "         [ 0.9414, -0.8223, -0.6779,  0.1547, -0.3171,  1.6001, -1.3324,\n",
            "           0.1818]]], grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Embeddings for Sentence 2:\n",
            " tensor([[[-0.6317, -0.5269, -1.1740,  2.2211,  1.4646,  0.5983,  0.1780,\n",
            "           0.9335],\n",
            "         [-0.0181,  0.5755,  0.8578,  0.2542,  1.3986, -0.3414,  0.0848,\n",
            "          -1.9094],\n",
            "         [-1.0302, -0.0383,  0.2648,  0.0040,  0.5926, -0.2198, -0.3749,\n",
            "           1.0893],\n",
            "         [ 0.0978, -0.8249, -0.1186, -1.2166, -0.0740,  2.1932, -0.0941,\n",
            "          -1.0248],\n",
            "         [ 1.1265, -0.1054,  0.1853, -1.2709,  0.1538,  0.2244,  0.6790,\n",
            "           0.5241]]], grad_fn=<EmbeddingBackward0>)\n",
            "\n",
            "Embeddings for Sentence 3:\n",
            " tensor([[[ 0.7050, -0.0054, -0.7490,  1.6957,  0.4317,  1.0350, -2.0611,\n",
            "          -0.4975],\n",
            "         [ 0.9414, -0.8223, -0.6779,  0.1547, -0.3171,  1.6001, -1.3324,\n",
            "           0.1818],\n",
            "         [-0.0181,  0.5755,  0.8578,  0.2542,  1.3986, -0.3414,  0.0848,\n",
            "          -1.9094],\n",
            "         [ 1.2439, -0.3636,  0.1571,  0.1304,  1.7929,  0.5730,  0.2452,\n",
            "          -0.7472],\n",
            "         [ 0.0978, -0.8249, -0.1186, -1.2166, -0.0740,  2.1932, -0.0941,\n",
            "          -1.0248]]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Create an Embedding Layer**\n",
        "Implement the embedding layer to convert token IDs into dense vectors."
      ],
      "metadata": {
        "id": "4khCooiqIdHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
        "embedded_tokens_1 = embedding_layer(token_ids_1)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens_1)\n",
        "embedded_tokens_2 = embedding_layer(token_ids_2)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens_2)\n",
        "embedded_tokens_3 = embedding_layer(token_ids_3)\n",
        "print(\"Embedded Tokens:\\n\", embedded_tokens_3)"
      ],
      "metadata": {
        "id": "LjWIeI7GIoEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28bd325c-c934-4596-fa3e-1a5fa0224158"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedded Tokens:\n",
            " tensor([[[ 0.5992, -0.3391,  0.6635,  0.4097,  0.8510, -0.2971,  0.8541,\n",
            "          -0.6802],\n",
            "         [ 1.4388,  0.9362,  0.0233,  0.0526,  0.1267, -1.7471,  0.2546,\n",
            "          -1.4998],\n",
            "         [ 0.5110,  0.5424,  1.2411, -0.5663,  0.5679, -0.9699,  0.1383,\n",
            "          -2.1414],\n",
            "         [ 0.2437,  0.2788,  0.5861,  0.0316, -2.1589, -0.3765, -0.7783,\n",
            "           0.6599],\n",
            "         [ 1.1690, -0.9870, -0.1704,  0.8806,  0.8097, -1.3048,  1.1746,\n",
            "           0.6297]]], grad_fn=<EmbeddingBackward0>)\n",
            "Embedded Tokens:\n",
            " tensor([[[-2.4727e-01, -1.1428e+00, -6.6926e-01,  2.2455e-01, -1.5599e+00,\n",
            "          -3.9196e-01, -1.3258e-01,  1.1621e+00],\n",
            "         [ 4.9729e-01,  1.3950e+00, -2.5457e-01,  1.8279e-01,  2.1942e-03,\n",
            "          -1.1572e+00,  3.5733e-01, -5.4347e-01],\n",
            "         [ 4.4993e-01, -7.2765e-01,  1.3750e+00, -7.0125e-01,  5.2682e-01,\n",
            "          -3.8529e-01,  2.8117e+00, -1.7598e+00],\n",
            "         [-6.4449e-01, -1.5905e+00, -1.3379e+00,  2.5243e+00,  6.0160e-01,\n",
            "           5.2089e-01, -9.0638e-01, -1.0032e+00],\n",
            "         [ 1.4388e+00,  9.3624e-01,  2.3310e-02,  5.2602e-02,  1.2670e-01,\n",
            "          -1.7471e+00,  2.5462e-01, -1.4998e+00]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n",
            "Embedded Tokens:\n",
            " tensor([[[ 5.1095e-01,  5.4238e-01,  1.2411e+00, -5.6631e-01,  5.6794e-01,\n",
            "          -9.6988e-01,  1.3827e-01, -2.1414e+00],\n",
            "         [ 1.1690e+00, -9.8697e-01, -1.7042e-01,  8.8061e-01,  8.0965e-01,\n",
            "          -1.3048e+00,  1.1746e+00,  6.2966e-01],\n",
            "         [ 4.9729e-01,  1.3950e+00, -2.5457e-01,  1.8279e-01,  2.1942e-03,\n",
            "          -1.1572e+00,  3.5733e-01, -5.4347e-01],\n",
            "         [ 5.9918e-01, -3.3911e-01,  6.6347e-01,  4.0975e-01,  8.5097e-01,\n",
            "          -2.9709e-01,  8.5408e-01, -6.8019e-01],\n",
            "         [-6.4449e-01, -1.5905e+00, -1.3379e+00,  2.5243e+00,  6.0160e-01,\n",
            "           5.2089e-01, -9.0638e-01, -1.0032e+00]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tAdd Positional Encoding**\n",
        "Incorporate positional encoding to provide positional information to the model.\n"
      ],
      "metadata": {
        "id": "EfdPOMcpG_qJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(seq_len, embedding_dim):\n",
        "    position = np.arange(seq_len)[:, np.newaxis]\n",
        "    div_term = np.exp(np.arange(0, embedding_dim, 2) * -(np.log(10000.0) / embedding_dim))\n",
        "    pe = np.zeros((seq_len, embedding_dim))\n",
        "    pe[:, 0::2] = np.sin(position * div_term)\n",
        "    pe[:, 1::2] = np.cos(position * div_term)\n",
        "    return torch.tensor(pe, dtype=torch.float)\n",
        "\n",
        "seq_len = token_ids_1.size(1)\n",
        "pos_encoding = positional_encoding(seq_len, embedding_dim)\n",
        "print(\"Positional Encoding:\\n\", pos_encoding)\n"
      ],
      "metadata": {
        "id": "Mti1h0tXHDXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ebbc22a-bcf5-455c-f4cf-1815d4f204b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encoding:\n",
            " tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
            "          1.0000e+00,  0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  5.4030e-01,  9.9833e-02,  9.9500e-01,  9.9998e-03,\n",
            "          9.9995e-01,  1.0000e-03,  1.0000e+00],\n",
            "        [ 9.0930e-01, -4.1615e-01,  1.9867e-01,  9.8007e-01,  1.9999e-02,\n",
            "          9.9980e-01,  2.0000e-03,  1.0000e+00],\n",
            "        [ 1.4112e-01, -9.8999e-01,  2.9552e-01,  9.5534e-01,  2.9996e-02,\n",
            "          9.9955e-01,  3.0000e-03,  1.0000e+00],\n",
            "        [-7.5680e-01, -6.5364e-01,  3.8942e-01,  9.2106e-01,  3.9989e-02,\n",
            "          9.9920e-01,  4.0000e-03,  9.9999e-01]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add the positional encoding to the embedded tokens:"
      ],
      "metadata": {
        "id": "iZm2hKp-HIxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_with_pos_1 = embedded_tokens_1 + pos_encoding.unsqueeze(0)\n",
        "print(\"Embedded Tokens with Positional Encoding:\\n\", embedded_with_pos_1)\n",
        "embedded_with_pos_2 = embedded_tokens_2 + pos_encoding.unsqueeze(0)\n",
        "print(\"Embedded Tokens with Positional Encoding:\\n\", embedded_with_pos_2)\n",
        "embedded_with_pos_3 = embedded_tokens_3 + pos_encoding.unsqueeze(0)\n",
        "print(\"Embedded Tokens with Positional Encoding:\\n\", embedded_with_pos_3)"
      ],
      "metadata": {
        "id": "TMwXiAIiHLm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf647ddd-058f-4b10-800b-ba47ebc80b4e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedded Tokens with Positional Encoding:\n",
            " tensor([[[ 0.5992,  0.6609,  0.6635,  1.4097,  0.8510,  0.7029,  0.8541,\n",
            "           0.3198],\n",
            "         [ 2.2803,  1.4765,  0.1231,  1.0476,  0.1367, -0.7472,  0.2556,\n",
            "          -0.4998],\n",
            "         [ 1.4203,  0.1262,  1.4398,  0.4138,  0.5879,  0.0299,  0.1403,\n",
            "          -1.1415],\n",
            "         [ 0.3848, -0.7112,  0.8816,  0.9869, -2.1289,  0.6230, -0.7753,\n",
            "           1.6599],\n",
            "         [ 0.4122, -1.6406,  0.2190,  1.8017,  0.8496, -0.3056,  1.1786,\n",
            "           1.6296]]], grad_fn=<AddBackward0>)\n",
            "Embedded Tokens with Positional Encoding:\n",
            " tensor([[[-2.4727e-01, -1.4277e-01, -6.6926e-01,  1.2245e+00, -1.5599e+00,\n",
            "           6.0804e-01, -1.3258e-01,  2.1621e+00],\n",
            "         [ 1.3388e+00,  1.9353e+00, -1.5473e-01,  1.1778e+00,  1.2194e-02,\n",
            "          -1.5722e-01,  3.5833e-01,  4.5653e-01],\n",
            "         [ 1.3592e+00, -1.1438e+00,  1.5737e+00,  2.7882e-01,  5.4682e-01,\n",
            "           6.1451e-01,  2.8137e+00, -7.5980e-01],\n",
            "         [-5.0337e-01, -2.5805e+00, -1.0424e+00,  3.4796e+00,  6.3160e-01,\n",
            "           1.5204e+00, -9.0338e-01, -3.1840e-03],\n",
            "         [ 6.8199e-01,  2.8260e-01,  4.1273e-01,  9.7366e-01,  1.6669e-01,\n",
            "          -7.4794e-01,  2.5862e-01, -4.9985e-01]]], grad_fn=<AddBackward0>)\n",
            "Embedded Tokens with Positional Encoding:\n",
            " tensor([[[ 5.1095e-01,  1.5424e+00,  1.2411e+00,  4.3369e-01,  5.6794e-01,\n",
            "           3.0116e-02,  1.3827e-01, -1.1414e+00],\n",
            "         [ 2.0104e+00, -4.4667e-01, -7.0588e-02,  1.8756e+00,  8.1965e-01,\n",
            "          -3.0487e-01,  1.1756e+00,  1.6297e+00],\n",
            "         [ 1.4066e+00,  9.7881e-01, -5.5897e-02,  1.1629e+00,  2.2193e-02,\n",
            "          -1.5737e-01,  3.5933e-01,  4.5653e-01],\n",
            "         [ 7.4030e-01, -1.3291e+00,  9.5899e-01,  1.3651e+00,  8.8096e-01,\n",
            "           7.0246e-01,  8.5708e-01,  3.1981e-01],\n",
            "         [-1.4013e+00, -2.2441e+00, -9.4849e-01,  3.4453e+00,  6.4159e-01,\n",
            "           1.5201e+00, -9.0238e-01, -3.1875e-03]]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Add a Feedforward Layer**"
      ],
      "metadata": {
        "id": "wfM3VX60HQ6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define a Feedforward Neural Network**\n",
        "Implement a simple feedforward layer as part of the encoder.\n"
      ],
      "metadata": {
        "id": "oUaKhCEuHViQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedforward = nn.Sequential(\n",
        "    nn.Linear(embedding_dim, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, embedding_dim)\n",
        ")\n",
        "ff_output = feedforward(embedded_with_pos_1)\n",
        "print(\"Feedforward Output:\\n\", ff_output)\n",
        "ff_output = feedforward(embedded_with_pos_2)\n",
        "print(\"Feedforward Output:\\n\", ff_output)\n",
        "ff_output = feedforward(embedded_with_pos_3)\n",
        "print(\"Feedforward Output:\\n\", ff_output)"
      ],
      "metadata": {
        "id": "RIN1MxZVHZwv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474dc42d-6b01-4c00-b60f-daa2d65d6c15"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feedforward Output:\n",
            " tensor([[[-0.1571,  0.0935,  0.0161, -0.2819,  0.1451,  0.1614, -0.2966,\n",
            "           0.0821],\n",
            "         [-0.2075,  0.1575, -0.1235, -0.2343,  0.1288,  0.3077, -0.0289,\n",
            "           0.0817],\n",
            "         [ 0.0547, -0.1875,  0.0627, -0.0278,  0.1793,  0.1280, -0.0423,\n",
            "           0.2004],\n",
            "         [-0.1711,  0.0078, -0.1642, -0.0315,  0.2445,  0.0642, -0.1423,\n",
            "           0.1153],\n",
            "         [-0.1161,  0.1205,  0.0069, -0.1451,  0.1816,  0.2675, -0.0855,\n",
            "           0.0290]]], grad_fn=<ViewBackward0>)\n",
            "Feedforward Output:\n",
            " tensor([[[-0.3326,  0.0317, -0.2559, -0.2773,  0.1369, -0.0585, -0.1441,\n",
            "           0.2352],\n",
            "         [-0.3508,  0.2016, -0.1888, -0.4201,  0.1795,  0.1333, -0.2951,\n",
            "           0.0887],\n",
            "         [ 0.4556, -0.2816,  0.2130, -0.0072,  0.0354,  0.1057,  0.2030,\n",
            "           0.2080],\n",
            "         [-0.1844,  0.5111,  0.0770,  0.1655, -0.0082,  0.3401,  0.3829,\n",
            "           0.0276],\n",
            "         [-0.1472, -0.0150, -0.0347, -0.0994,  0.1801,  0.1836, -0.1619,\n",
            "           0.1063]]], grad_fn=<ViewBackward0>)\n",
            "Feedforward Output:\n",
            " tensor([[[-0.0572, -0.1770,  0.1549, -0.3124,  0.1340,  0.0982, -0.3121,\n",
            "           0.2355],\n",
            "         [-0.0528,  0.0394,  0.0058, -0.1556,  0.1228,  0.3997,  0.0404,\n",
            "           0.0938],\n",
            "         [-0.2333,  0.1631, -0.1755, -0.2071,  0.1622,  0.2354, -0.1743,\n",
            "           0.0742],\n",
            "         [ 0.0714,  0.1383,  0.0886,  0.1675,  0.1652,  0.3091,  0.0290,\n",
            "          -0.0216],\n",
            "         [-0.3164,  0.4926,  0.0245,  0.0008, -0.0184,  0.1975,  0.3484,\n",
            "           0.0614]]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 3: Combine the Components into an Encoder Block**"
      ],
      "metadata": {
        "id": "xb9uak0OHcjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\t**Define the Encoder Block**\n",
        "Combine the embedding, positional encoding, and feedforward components into an encoder block.\n"
      ],
      "metadata": {
        "id": "qXVdYvwkHgdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.feedforward = nn.Sequential(\n",
        "            nn.Linear(embedding_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, embedding_dim)\n",
        "        )\n",
        "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embed = self.embedding(x)\n",
        "        pos_enc = positional_encoding(x.size(1), embed.size(2))\n",
        "        embed_with_pos = embed + pos_enc.unsqueeze(0)\n",
        "        ff_output = self.feedforward(embed_with_pos)\n",
        "        return self.layer_norm(embed_with_pos + ff_output)\n",
        "\n",
        "encoder = TransformerEncoderBlock(vocab_size, embedding_dim)\n",
        "output = encoder(token_ids_1)\n",
        "print(\"Encoder Output:\\n\", output)\n",
        "output = encoder(token_ids_2)\n",
        "print(\"Encoder Output:\\n\", output)\n",
        "output = encoder(token_ids_3)\n",
        "print(\"Encoder Output:\\n\", output)\n"
      ],
      "metadata": {
        "id": "70IMzzkPHmRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fe869b3-6513-41bc-87ce-f8ae4c4fac45"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Output:\n",
            " tensor([[[-0.9931, -0.0568,  0.0662,  1.6722, -1.1605,  0.3061, -1.0908,\n",
            "           1.2567],\n",
            "         [-0.7680, -0.9188,  0.2827, -1.3189,  0.0515,  1.9645, -0.2098,\n",
            "           0.9168],\n",
            "         [ 0.4904, -1.3195, -1.1697, -1.1967,  0.5845,  1.2958,  0.2502,\n",
            "           1.0650],\n",
            "         [ 0.2816, -2.2282, -0.3123,  1.1132, -0.2728,  1.2251, -0.0148,\n",
            "           0.2082],\n",
            "         [-1.4596, -0.1393,  0.3228,  1.4708, -0.5630, -0.4751, -0.7369,\n",
            "           1.5802]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Encoder Output:\n",
            " tensor([[[-1.3450,  0.2081,  0.8977,  1.2969, -1.7840,  0.5439, -0.1959,\n",
            "           0.3783],\n",
            "         [ 0.6199,  1.1988,  0.4147,  0.7988, -1.7309,  0.1333, -1.5314,\n",
            "           0.0967],\n",
            "         [ 1.2797, -0.3752,  1.5477, -0.0791,  0.0944, -0.2915, -1.9122,\n",
            "          -0.2637],\n",
            "         [-0.0841, -1.5040, -0.3662,  1.5027,  0.0521, -0.2158, -0.9373,\n",
            "           1.5527],\n",
            "         [-1.6643, -1.2346,  0.4919, -0.4657,  0.7313,  1.4379, -0.0939,\n",
            "           0.7974]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "Encoder Output:\n",
            " tensor([[[-0.7368,  0.6694, -1.5488, -1.3110,  0.4524,  1.2738,  0.1867,\n",
            "           1.0145],\n",
            "         [-0.4420,  0.6097,  0.2581,  1.2182, -1.6464, -0.6701, -0.7810,\n",
            "           1.4535],\n",
            "         [ 0.8533,  0.2748,  0.5664,  1.0697, -1.7232,  0.3134, -1.6116,\n",
            "           0.2573],\n",
            "         [-0.6869, -1.3307,  0.1550,  1.7075, -0.5770,  0.3835, -0.8927,\n",
            "           1.2413],\n",
            "         [-0.6794, -1.1331, -0.3257,  1.5456,  0.2176, -0.2426, -1.0069,\n",
            "           1.6246]]], grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 4: Experiment with Different Inputs**\n",
        "\n",
        "* Test with Different Sentences\n",
        "Replace token_ids with new examples to observe how the encoder processes different inputs.\n",
        "* Modify Hyperparameters\n",
        "Experiment with different embedding sizes, feedforward dimensions, or positional encoding scales to see their effect on the output.\n"
      ],
      "metadata": {
        "id": "zfB-L5zlHqhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary**"
      ],
      "metadata": {
        "id": "IZW4m09oIIFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By completing this lab, you have:\n",
        "\n",
        "* Understood the role of embedding, positional encoding, and feedforward layers in the Transformer encoder.\n",
        "* Gained hands-on experience implementing a core component of the Transformer architecture.\n",
        "* Developed a deeper appreciation for the architecture’s design and functionality.\n",
        "\n",
        "This lab builds foundational knowledge of the Transformer, preparing you for more advanced concepts like self-attention.\n"
      ],
      "metadata": {
        "id": "49Ko4E9cH4df"
      }
    }
  ]
}